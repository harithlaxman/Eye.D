{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EyeSpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time as tm\n",
    "import argparse\n",
    "from imageai import Detection\n",
    "from scipy.stats import itemfreq\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path = os.getcwd()\n",
    "VID_PATH = './demos/trial1.mp4'\n",
    "CONTINUITY_THRESHOLD = 8 #For cutting out boxes\n",
    "\n",
    "MIN_SECONDS = 1 # (seconds) Minimum duration of a moving object\n",
    "INTERVAL_BW_DIVISIONS = 5 # (seconds) For distributing moving objects over a duration to reduce overlapping.\n",
    "GAP_BW_DIVISIONS = 1.5 #(seconds)\n",
    "FRAMES_PER_DETECTION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "detector = Detection.ObjectDetection()\n",
    "detector.setModelTypeAsTinyYOLOv3()\n",
    "detector.setModelPath(\"./Test/Models/yolo-tiny.h5\")\n",
    "detector.loadModel()\n",
    "custom_objects = detector.CustomObjects(car=True, motorcycle=True, person=True,  bicycle=True, bus=True, truck=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output of detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# detections = detector.detectCustomObjectsFromImage(custom_objects=custom_objects, input_image=os.path.join(execution_path , \"rec.jpg\"), output_image_path=os.path.join(execution_path , \"test.jpg\"), minimum_percentage_probability=31)\n",
    "detected_image_array, detections = detector.detectCustomObjectsFromImage(\n",
    "                                        output_type='array',\n",
    "                                        custom_objects=custom_objects, \n",
    "                                        input_image=os.path.join(execution_path , \"rec.jpg\"), \n",
    "                                        minimum_percentage_probability=45\n",
    "                                    )\n",
    "frame = cv2.imread('rec.jpg')\n",
    "for eachObject in detections:\n",
    "    rect = eachObject[\"box_points\"]\n",
    "    cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")\n",
    "cv2.imshow('frame', detected_image_array)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(VID_PATH)\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "frames = []\n",
    "masks = []\n",
    "ind = 0\n",
    "start_time = tm.time()\n",
    "all_conts = []\n",
    "all_types = []\n",
    "avg2 = None\n",
    "while(vid.isOpened()):\n",
    "    \n",
    "    # Background Extraction\n",
    "    if(avg2 != None): cv2.accumulateWeighted(frame, avg2, 0.01)\n",
    "    ret,frame = vid.read()\n",
    "    if(not ret): break;\n",
    "    \n",
    "    if(avg2): avg2 = np.float32(frame)\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    # Running detection for every FRAMES_PER_DETECTION\n",
    "    if(ind%FRAMES_PER_DETECTION == 0):\n",
    "        frames.append(frame)\n",
    "        detected_image_array, detections = detector.detectCustomObjectsFromImage(\n",
    "            input_type=\"array\",\n",
    "            output_type='array',\n",
    "            custom_objects=custom_objects,\n",
    "            input_image=frame, \n",
    "            minimum_percentage_probability=50\n",
    "        )\n",
    "        types = []; conts = []\n",
    "        for eachObject in detections:\n",
    "            rect = eachObject[\"box_points\"]\n",
    "            conts.append(np.array([rect[0],rect[1],rect[2]-rect[0],rect[3]-rect[1]]))\n",
    "            types.append(eachObject[\"name\"])\n",
    "        print(ind//FRAMES_PER_DETECTION, end=' ')\n",
    "        all_conts.append(np.array(conts))\n",
    "        all_types.append(types)\n",
    "        masks.append(fgmask)\n",
    "        cv2.imshow('frame', fgmask)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    ind += 1\n",
    "masks = np.array(masks)\n",
    "frames = np.array(frames)\n",
    "print(\"--- %s seconds ---\" % (tm.time() - start_time))\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:28:31.646976Z",
     "start_time": "2019-10-19T19:28:31.638977Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_centres(p1):\n",
    "    return np.transpose(np.array([p1[:,0] + p1[:,2]/2, p1[:,1] + p1[:,3]/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:31:26.097783Z",
     "start_time": "2019-10-19T19:31:26.089806Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    p1 = np.expand_dims(p1, 0)\n",
    "    if p2.ndim==1:\n",
    "        p2 = np.expand_dims(p2, 0)\n",
    "        \n",
    "    c1 = get_centres(p1)\n",
    "    c2 = get_centres(p2)\n",
    "    return np.linalg.norm(c1 - c2, axis=1)\n",
    "\n",
    "def get_nearest(p1, points):\n",
    "    \"\"\"returns index of the point in *points* that is closest to p1\"\"\"\n",
    "    return np.argmin(distance(p1, points)), np.min(distance(p1, points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:31:27.682098Z",
     "start_time": "2019-10-19T19:31:27.674049Z"
    }
   },
   "outputs": [],
   "source": [
    "class box:\n",
    "    def __init__(self, coords, time, otype):\n",
    "        self.coords = coords #coordinates\n",
    "        self.time   = time #nth frame/time\n",
    "        self.type   = otype\n",
    "        \n",
    "class moving_obj:\n",
    "    def __init__(self, starting_box):\n",
    "        self.boxes = [starting_box]\n",
    "        self.type = None\n",
    "        self.img = None\n",
    "        self.mask = None\n",
    "        self.color = None\n",
    "        \n",
    "    def add_box(self, box):\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    def last_coords(self):\n",
    "        return self.boxes[-1].coords\n",
    "    \n",
    "    def age(self, curr_time):\n",
    "        last_time = self.boxes[-1].time\n",
    "        return curr_time - last_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:34.786499Z",
     "start_time": "2019-10-19T16:45:34.269648Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Will associate boxes into objects\"\"\"\n",
    "#old - boxes in the previous frame\n",
    "#new - boxes in the current frame\n",
    "\n",
    "\n",
    "moving_objs = []\n",
    "\n",
    "for curr_time, new_boxes in enumerate(all_conts): #iterating over frames\n",
    "    if len(new_boxes) != 0: #if not empty\n",
    "        new_assocs = [None]*len(new_boxes) #all new boxes initially are not associated with any moving_objs\n",
    "        obj_coords = np.array([obj.last_coords() for obj in moving_objs if obj.age(curr_time)<CONTINUITY_THRESHOLD])\n",
    "        unexp_idx = -1 #index of unexpired obj in moving_objs\n",
    "        for obj_idx, obj in enumerate(moving_objs):\n",
    "            if obj.age(curr_time) < CONTINUITY_THRESHOLD: #checking only unexpired objects\n",
    "                unexp_idx += 1\n",
    "                nearest_new, dst1 = get_nearest(obj.last_coords(), new_boxes) #nearest box to obj\n",
    "                nearest_obj, dst = get_nearest(new_boxes[nearest_new], obj_coords) #nearest obj to box\n",
    "\n",
    "                if nearest_obj==unexp_idx: #both closest to each-other\n",
    "                    #associate\n",
    "                    if(dst < 100):\n",
    "                        new_assocs[nearest_new] = obj_idx\n",
    "    \n",
    "    \n",
    "    for new_idx, new_coords in enumerate(new_boxes):\n",
    "        new_assoc = new_assocs[new_idx]\n",
    "        new_box = box(new_coords, curr_time, all_types[curr_time][new_idx])\n",
    "\n",
    "        if new_assoc is not None: \n",
    "            #associate new box to moving_obj\n",
    "            moving_objs[new_assoc].add_box(new_box)\n",
    "        else: \n",
    "            #add a fresh, new moving_obj to moving_objs\n",
    "            new_moving_obj = moving_obj(new_box)\n",
    "            moving_objs.append(new_moving_obj)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:34.795924Z",
     "start_time": "2019-10-19T16:45:34.789026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing objects that occur for a very small duration\n",
    "\n",
    "MIN_FRAMES = MIN_SECONDS*(fps//3)\n",
    "\n",
    "moving_objs = [obj for obj in moving_objs if (obj.boxes[-1].time-obj.boxes[0].time)>=MIN_FRAMES]\n",
    "len(moving_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying result for an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND = 27\n",
    "boxes = moving_objs[IND].boxes\n",
    "outv = frames.copy()\n",
    "for rect in boxes:\n",
    "    x,y,w,h = map(int, list(rect.coords))\n",
    "    cv2.rectangle(outv[rect.time], (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "out = cv2.VideoWriter('out_summary.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, (800,480))\n",
    "for frame in outv:\n",
    "    cv2.imshow('Video summary',frame)\n",
    "    out.write(frame)\n",
    "    tm.sleep(0.01)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "#     tm.sleep(1/30) #TODO: FPS\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing contours detected\n",
    "for frame in masks:\n",
    "    ret,thresh1 = cv2.threshold(frame,1,255,cv2.THRESH_BINARY)\n",
    "    cv2.imshow('frame', thresh1)\n",
    "    tm.sleep(0.01)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(img):\n",
    "    cv2.imshow(\"frame\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()  \n",
    "\n",
    "def showColor(c):\n",
    "    color = np.ones((100,100,3))\n",
    "    for i in range(3):\n",
    "        color[:,:,i] = color[:,:,i]*(c[i])/255\n",
    "    showImg(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColor(img, mask):\n",
    "    car = []\n",
    "    X,Y,_ = img.shape\n",
    "    for x in range(X):\n",
    "        for y in range(Y):\n",
    "            if(not mask[x,y]): continue;\n",
    "            car.append(img[x,y,:])\n",
    "    car = np.float32(np.array(car))\n",
    "\n",
    "    # number of clusters\n",
    "    n_colors=2\n",
    "\n",
    "    #number of iterations\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "\n",
    "    #initialising centroid\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "    #applying k-means to detect prominant color in the image\n",
    "    _, labels, centroids = cv2.kmeans(car, n_colors, None, criteria, 10, flags)\n",
    "\n",
    "    # i = np.argmax(np.unique(labels, return_counts=True)[1])\n",
    "    i = np.argmax(np.sum(centroids, 1))\n",
    "    return(centroids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing findColor for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND = 1\n",
    "img = cv2.imread(\"./result/\"+str(IND)+\".jpg\")\n",
    "mask = cv2.imread(\"./result/a\"+str(IND)+\".jpg\",0)\n",
    "showImg(img)\n",
    "\n",
    "color = findColor(img, mask)\n",
    "showColor(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting type and image for objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,obj in enumerate(moving_objs):\n",
    "    boxes = obj.boxes\n",
    "    g = 0\n",
    "    mx = 0\n",
    "    otype = {}\n",
    "    for rect in boxes:\n",
    "        x,y,w,h = map(int, list(rect.coords))\n",
    "        area = w*h\n",
    "        if(area > mx):\n",
    "            mx = area\n",
    "            mx_i = g\n",
    "            cv2.imwrite('./test/'+str(i)+'_'+str(g)+'.jpg', frames[rect.time, y:y+h, x:x+w])\n",
    "        if(rect.type not in otype): otype[rect.type] = 0;\n",
    "        otype[rect.type] += 1\n",
    "        g += 1\n",
    "    moving_objs[i].type = max(otype, key=otype.get)\n",
    "    rect = boxes[mx_i]\n",
    "    x,y,w,h = map(int, list(rect.coords))\n",
    "    cv2.imwrite('./result/'+str(i)+'.jpg', frames[rect.time, y:y+h, x:x+w])\n",
    "    ret,thresh = cv2.threshold(masks[rect.time],1,255,cv2.THRESH_BINARY)\n",
    "    cv2.imwrite('./result/a'+str(i)+'.jpg', thresh[y:y+h, x:x+w])\n",
    "    moving_objs[i].img = frames[rect.time, y:y+h, x:x+w]    \n",
    "    moving_objs[i].mask = thresh[y:y+h, x:x+w]\n",
    "    moving_objs[i].color = findColor(moving_objs[i].img, moving_objs[i].mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECONDS_PER_3FRAME = 3/fps\n",
    "with open('out.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i,obj in enumerate(moving_objs):\n",
    "        writer.writerow([i, obj.type, obj.color[0], obj.color[1], obj.color[2], \n",
    "                         obj.boxes[0].time*SECONDS_PER_3FRAME,\n",
    "                         obj.boxes[-1].time*SECONDS_PER_3FRAME\n",
    "                        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python36764bitb4078c42e20c457aad221add00386046"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
